# The problem

A reproducibility crisis in medical sciences has been widely acknowledged, but few researchers and fewer journals have adopted standards to increase computational reproducibility. 

Several large datasets are used for tens of thousands of cancer studies. Given the central role of these data and the proliferation of tools to support reproducible research, a lack of reproducibility materials should be unacceptable. 

The context for secondary analysis development encouraged minimizing barriers to results, rather than maximizing the truth value of a result. 
Cite ecologist who published wrong stuff

This work is meant to describe technology-agnostic standards for reproducibility of secondary data analysis projects. 

# Definitions 

Reproducibility - The same experiment can be performed under the same conditions, and yields the same results. 

Replication - The same experiment performed under different conditions, often with the expectation of agreement with previous research. 

Open - Aside from protected data, that all materials used for analysis development are made public. 


# The standard 

The proposed litmus test for data analysis reproducibility is: *Have at least two study authors wholly performed a reported analysis?*

If two authors have performed the exact same steps and produced the same results, that study is reproducible. 


# Project workflow

1. Given data
2. Don't mess with data
3. Don't mess with data
4. Save transformations in cache
5. Don't mess with data
6. Write source code in a predictable format
7. Ask a co-author (peer in a similar field) to perform the analysis from source


# Affirmation  

By acknowledging that the proposed standard for reproducibility was met, a manuscript is immediately more credible than competing work. Attestation of reproducibility has become more widespread in other disciplines, but not as often in medical research.  




# Conclusions  






Laboratory standards are dictated by the requirements of a natural setting. Computational standards are mostly arbitrary. The growing ecosystem of manuscripts that are heavily dependent on accurate computation, then, reflects the pressures that those authors faced. At the moment, this means publishing as much as possible. 








